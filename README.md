
# USP-PPGSI-SIN5021 - Probabilistic Planning and Reinforcement Learning

Repository for the [SIN5021](https://uspdigital.usp.br/janus/componente/disciplinasOferecidasInicial.jsf?action=3&sgldis=SIN5021) graduate course Planning and Reinforcement Learning

# Reports:

 1. [Avaliação de algoritmos para MDPs](Report1)
 2. TBD
 
# Syllabus

**Objectives:** To study the theoretical fundamentals, techniques and main approaches used in probabilistic planning and reinforcement learning in Artificial Intelligence.

**Rationale:** The aim of this elective course is to complement the training of students, especially those interested in Artificial Intelligence. Planning is one of the most important challenges in this area that allows to increase the autonomy and flexibility of intelligent systems and involves the generation of a sequence of actions to transform an initial situation in a final situation. The planning techniques have been applied in a wide variety of tasks, including: robotics, planning of industrial processes, logistics / transportation, web services composition, planning for recovery of information, planning of autonomous agents, among others. The reinforcement learning is an alternative solution to the tasks mentioned before when the dynamics of the tasks can not be obtained a priori. Thus, the reinforcement learning solves the planning problem through interactions with the environment using a trial and error strategy.

**Content:** The following topics will be addressed: the problem of planning, classic and probabilistic planning, Markov decision processes and the existence of solutions, Policy Iteration and Value Iteration algorithms, factored Markov decision processes and basic algorithms, heuristic search algorithms, symbolic algorithms, approximation algorithms, extensions of Markov decision processes and applications, the reinforcement learning problem, the problem of prediction and solution for temporal difference, stochastic dynamic programming, Q-learning, Sarsa and prioritized Sweeping algorithms, spatial approximation, temporal approximation, batch learning and transfer learning.

1. Introduction and motivation. The planning task. Classical and probabilistic planning.
2. Basic concepts about Markov decision processes and the existence of solutions. Factored Markov decision processes.
3. Basic algorithms for MDPs: policy iteration, value iteration and linear programming formulation.
4. Heuristic search algorithms for MDPs: LAO *, RTDP and extensions, among others.
5. Symbolic algorithms for factored MDPs: SPUDD, Symbolic LAO *, among others.
6. Approximate algorithms for MDPs, UCT, use of inadmissible heuristics, approximate policy iteration and approximate linear programming.
7. Extensions of Markov decision processes: continuous MDPs, MDPs with imprecise probabilities, relational MDPs.
8. Application of Probabilistic Planning: robotics, planning of industrial processes, logistics / transportation, web services composition, etc.
9. Prediction in RL: Monte Carlo and Temporal Difference.
10. Control in RL: Stochastic Dynamic Programming.
11. Traditional algorithms for RL: Q-Learning, Sarsa, Sweeping.
12. Spatial Approximation in RL: CMAC.
13. Temporal Approximation in RL: options.
14. Batch Reinforcement Learning.
15. Transfer Learning.

**Type of Assessment:** Grades will be assigned to exams and assignments involving the implementation and evaluation of algorithms. The final score is calculated by the weighted averag

**Bibliography:**

\[1\] Mausam and Andrey Kolobov. Planning with Markov Decision Processes: An AI Perspective. Synthesis Lectures on Artificial Intelligence and Machine Learning. Morgan & Claypool publishers, 2012.<br/>
\[2\] Csaba Szepesvari. Algorithms for Reinforcement Learning. Synthesis Lectures on Artificial Intelligence and Machine Learning. Morgan & Claypool publishers, 2013.<br/>
\[3\] Sutton and Barto. Reinforcement Learning: an Introduction, 1998.<br/>
\[4\] Van Otterlo and Wiering. Reinforcement Learning, 2012.<br/>
\[5\] Bertsekas. Abstract Dynamic Programming, 2013.<br/>
\[6\] C. Guestrin, D. Koller, R. Parr and S. Venkataraman. Efficient solution algorithms for factored MDPs. JAIR 19, pp. 399-468, 2003.<br/>
\[7\] C. Boutilier, T. Dean and S. Hanks. Decision-Theoretic planning: Structural assumptions and computational leverage. JAIR 11, pp. 1-94, 1999.<br/>
\[8\] Stuart Russel and Peter Norvig. Artificial Intelligence: A Modern Approach, 2 ed., Prentice Hall, 2002.<br/>
\[9\] Dana Nau, Malik Ghallab, and Paolo Traverso. Automated Planning: Theory & Practice. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2004.
